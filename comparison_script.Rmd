---
title: "Dimension Reduction - Comparison Script for R"
author: "Giménez Gredilla, Daniel"
date: "November 2017"
bibliography: library.bib
output:
  pdf_document: 
    keep_tex: yes
    fig_caption: yes
    includes:
      in_header: tex-support.tex
    toc: yes
    toc_depth: 2
options:
  encoding: utf8
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.lp = "Fig. ", tidy.opts=list(width.cutoff=60),tidy=TRUE, cache = TRUE, fig.width=12, fig.height=4, comment = NULL, out.height='200px', dpi=200, fig.pos = 'h', out.extra = '', engine.path = list(python = 'C:/Program Files (x86)/eMule/python/python.exe'))
```

```{r library_load, echo=FALSE, message=FALSE}
require(knitr)
require(stats)
require(caret)
require(e1071)
require(ica)
require(psych)
require(MASS)
require(ggplot2)
require(ggfortify)
#require(DMwR)
```

\pagebreak  

#1 - Introduction and general data set description  

```{r data_var_declare, include=FALSE, echo=FALSE}
data_class_factors <- 7
data_class_numeric <- 2867
data_response_index <- 2

```

```{r data_load, include=FALSE, echo=FALSE}
#Tipos de variable por columna
colClasses <- append(c(rep("factor",data_class_factors)),c(rep("numeric",data_class_numeric)))
#Carga de los datos del CSV
data_df <- read.csv2(file = "data/data.csv", sep = ",", dec = ".", colClasses = colClasses, stringsAsFactors = FALSE)
#Fórmula del modelo
data_formula <- as.formula(paste(colnames(data_df[data_response_index]), "~", paste(colnames(data_df)[-(1:data_class_factors)], collapse=" + ")))
#Balancear datos con SMOTE. ROSE sólo funciona para clasificaciones binarias.
#data_df <- SMOTE(data_formula, perc-over = 200, perc.under = 200, k = 5)

#Semilla para aleatorización controlada
set.seed(123)

#Subsets de predictores y respuestas
data_df_predictors <- data_df[,8:2874]
data_df_predictors <- scale(data_df_predictors)
data_df_responses <- data_df[,data_response_index]

#Índices para training
data_train_index <- sample(1:nrow(data_df), ceiling(nrow(data_df)*.66))
write.table(as.vector(data_train_index), file = "data/data_train_index.csv",row.names=FALSE,col.names=FALSE, sep=",")

#Subset de respuestas de training
data_df_train_responses <- data_df_responses[data_train_index]
#Subset de respuestas de test
data_df_test_responses <- data_df_responses[-data_train_index]

```

The current data set is a study on **normal**, **atypical**, and **variant** lymphocytes, in which 2867 numerical variables, based on colorimetric and geometric features have been measured. The aim of the study is more thoroughly explained both in the proposal and main report for this project.  

The current data set has `r length(data_df[,1])` observations for `r length(data_df[1,])` variables, of which `r data_class_factors` (in which the response variable, *tipoCelula*, is included) are factors and `r data_class_numeric` are numeric predictor variables.   

The response variable, *tipoCelula*, has three levels, being these **ATYPICAL_LYMPHOCYTE**, **VARIANT_LYMPHOCYTE** and **LYMPHOCYTE**. Two subsets will be generated with this data, a training set comprising 66% of all data, and a test set formed by the remaining entries. Both sets are generated by defining a random seed with the *set.seed()* function (the seed beeing 123) and applying that seed to the *sample()* function to generate an array of indexes.  


```{r data_pca_features_number, include=FALSE, echo=FALSE}
#Calcular componentes principales
data_pca <- prcomp(data_df_predictors)
#Sacar el sumario de la PCA.
data_pca_summary <- summary(data_pca)
#Calcular las features que explican al menos el 95% de la varianza
for (i in seq(from = 10, to = 250, by = 10)) {
  data_varExp <- sum(data_pca_summary$importance[2,1:i])
  if (data_varExp >= 0.95) {
    varImpMessage <- paste("For ", i, " components, the percentage of variance explained is ",data_varExp, ".", sep = '')
    data_optimal_exfeat <- i
    return(print(varImpMessage))
  }
}
```

#2 - Goals and techniques  

This script aims to assess the comparative performances of different dimension reduction techniques. They will be measured for a common accuracy metric and judged by their processing performance. Being **PCA** the most used, most assessed technique, it will be used as a kind of touchstone in respect to requirements for the other techniques.  

For the effects of this project, the benchmark amount of variables is that number which satisfies one condition, being this that the extracted features account for an accumulated 95% of variance in the reference dimensionality reduction technique, **PCA**. Having determined this, a continued test of cumulative numbers of extracted features, between a floor of 10 and an estimative limit of 250 yields the following result.  

```{r data_exfeat_message, include = FALSE, results='asis'}
cat(varImpMessage)
```

With this number of extracted features as an objective benchmark, the following techniques will be conducted:  

- **PCA**  
- **ICA**  
- **Factor Analysis**  
- **Linear Decomposition Analysis**  

The resulting features will then be divided in training and test sets, and used as input, first, for the fitting and training of an **SVM** function (*svm()*, from the *caret* package), and then as input of a *predict()* function, from the *stats* package. The predicted classes will then be cross-tested with the actual test classes. A confusion matrix and a Cohen's Kappa weighted and unweighted value will then be output, and used as that technique's entry in the final performance comparison.  

**Cohen's Kappa** [@Luengo2009] is an alternative to **Classification Rate** that takes into account random correct hits. It was originally used to measure the degree of agreement between two subjects describing the same event. In the meantime it has been adapted for classification tasks, as it compensates for random hits in the same way that **AUC** does for **ROC**. The mathematical expression for **Cohen's Kappa** is applied to the contingency table of an event in the following way:  

$kappa = \frac{n \sum_{i=1}^C x_{ii} - \sum_{i=1}^C x_{i.}x_{.i}}{n^2 - \sum_{i=1}^C x_{i.}x_{.i}}$  

Where $x_{ii}$ is the cell count in the main diagonal, *n* is the number of examples, *C* is the number of class values and $x_{.i}x_{i.}$ are the total columns and rows counts, respectively.  

The value range of **Cohen's Kappa** goes from -1 (total disagreement) to 1 (perfect agreement).

The reasons for chosing **Cohen's Kappa** as accuracy metric are as follows:  

- The data set upon which it is going to be used has a multiclass factor response variable.  
- Those labels are not ascribable to a binary synthetic class system.  
- **Cohen's Kappa** yields a scalar, simple value well suited for multiclass classification.  
- It is more powerful than other multiclass accuracy metrics such as **Classification Rate**, because it takes into account random hits, scoring successes separately for each class and aggregating them.  

Weighted and unweighted values of **Cohen's Kappa** differ, as their name implies, in that weighted scores take into account the differential weights of several levels of disagreement between observed and predicted classes. This is a level of information that is lost in binary classification, as all disagreements between observed and predicted classes share the same level of disagreement.  

#3 - Dimension Reduction Techniques  

##3.1 - PCA  

PCA is the most used unsupervised, linear dimension reduction technique currently available. It is also the best, in the mean-square error sense [@Fodor2002]. Its central idea is the construction of a set of features from a number of initial variables [@Jolliffe2002]. The number of new features will be less than the initial variables, while retaining as much as possible of the initial variation. This is achieved by linear transformations of the original data, and then establishing a descending order of the new features attending to the amount of variation retained or explained by each of them.  

For this project, `r data_optimal_exfeat` are retained and use in the fitting, training and prediction of classes. The following section depicts the results of this protocol.  

```{r data_pca, include=FALSE, echo=FALSE}
#De los componentes principales, escoger los primeros 210
data_pca_exfeat <- data_pca$x[,1:data_optimal_exfeat]
#Generar los sets de training y test
data_pca_train <- subset(data_pca_exfeat[data_train_index,])
data_pca_test <- subset(data_pca_exfeat[-data_train_index,])
#Ajustar una SVM con las 20 componentes principales extraídas
data_pca_svm <- svm(data_pca_train, y = data_df_train_responses, type = "C-classification", kernel = "radial")
#Usar esa SVM para predecir las respuestas
data_pca_predict <- stats::predict(data_pca_svm, data_pca_test)
#Tabular y sacar la Kappa de Cohen
data_pca_table <- table(data_pca_predict, data_df_test_responses)
data_pca_perc_table <- prop.table(data_pca_table)*100
data_pca_perc_hit <- sum(diag(data_pca_perc_table))
data_pca_cohen <- cohen.kappa(data_pca_table, n.obs = length(data_df_test_responses))
```

After fitting and predicting, the  hit and accuracy values are extracted and represented in **Table 1** and **Table 2**, in absolute and percentage values, respectively.  

```{r data_pca_table, echo=FALSE, results='asis'}
kable(data_pca_table, caption = 'PCA observed versus predicted results', digits = 2, format = "latex")
```

```{r data_pca_perc_table, echo=FALSE, results='asis'}
kable(data_pca_perc_table, caption = 'PCA observed versus predicted results - percentages', digits = 2, format = "latex")
```

**PCA** yields a weighted Cohen's Kappa value of `r round(data_pca_cohen$weighted, 2)`, which will be a benchmark for other techniques.

As a visual, informative measure, it is interesting to have the pca fitted components plotted, coloured by *tipoCelula* label.  

```{r data_pca_autoplot, echo=FALSE, results='asis'}
#autoplot(data_pca, data = data_df, colour = 'tipoCelula')
```

Points in space are grouped by factors and colored by response label.

##3.2 - ICA  

Independent Component Analysis (*ICA*) is a statistical method for transforming an observed multidimensional random vector into components that are statisticaly as independent from each other as possible, this is, a tendency to **redundancy reduction** [@Tobergte2013]. In its linear approach, as with other dimension reduction algorithms, its goal is to take a zero-mean, *m*-dimensional variable, and by means of a linear transformation, find its *n*-dimensional transform, such that $n \le m$, this transformation having some suitable properties. The vectors obtained from this transformation are neither orthogonal nor ranked in order.  

Feature extraction is a prominent application of *ICA*. It is originally motivated by results in neuroscience that suggest that the same cited principle of redundancy reduction is applied by the brain for the early processing of sensory data.  

*ICA* is a generative model (it describes how the observed data are generated by describing the components), and it seeks the minimization of mutual information between the transformed variables. It depends on the supposition of nongaussianity for the data; gaussian data is independent and of mean zero, it has no skewness and as such can only be estimated up to an orthogonal transformation [@Hyvarinen2000].  

Applying it to the current data set, the results are as follows:  

```{r data_ica, include=FALSE, echo=FALSE}
#Extraer 210 features
data_ica <- icafast(data_df_predictors, nc = data_optimal_exfeat)
data_ica_exfeat <- data_ica$S
#Generar los sets de training y test
data_ica_train <- subset(data_ica_exfeat[data_train_index,])
data_ica_test <- subset(data_ica_exfeat[-data_train_index,])

#Someter esas 210 features (la matriz de señales S) a SVM
data_ica_svm <- svm(data_ica_train, y = data_df_train_responses, type = "C-classification", kernel = "radial")
#Predecir con el modelo ajustado las respuestas
data_ica_predict <- stats::predict(data_ica_svm, data_ica_test)
#Tabular datos y sacar Kappa de Cohen
data_ica_table <- table(data_ica_predict, data_df_test_responses)
data_ica_perc_table <- prop.table(data_ica_table)*100
data_ica_perc_hit <- sum(diag(data_ica_perc_table))
data_ica_cohen <- cohen.kappa(data_ica_table, n.obs = length(data_df_test_responses))
```

After fitting and predicting, the  hit and accuracy values are extracted and represented in **Table 3** and **Table 4**, in absolute and percentage values, respectively.  

```{r data_ica_table, echo=FALSE, results='asis'}
kable(data_ica_table, caption = 'ICA observed versus predicted results', digits = 2, format = "latex")
```

```{r data_ica_perc_table, echo=FALSE, results='asis'}
kable(data_ica_perc_table, caption = 'ICA observed versus predicted results - percentages', digits = 2, format = "latex")
```

Curiously, **ICA** yields results similar to **PCA**, with a weighted Cohen's Kappa of `r round(data_ica_cohen$weighted, 2)`. Even though this puts it at eye level with **PCA**, the processing power needed for this technique is noticeably larger, and thus, the hollistic assessing of **ICA** still has it behind **PCA**.

```{r data_ica_autoplot, echo=FALSE, results='asis'}
#plot(data_ica)
```

```{r data_garbage_collect_1, include=FALSE, echo=FALSE}
gc()
```

##3.3 - Factor Analysis  

The basic idea underlying Factor Analysis is that *p* observed random variables, **x**, can be expressed, except for an error term, as linear functions of $m(<p)$ hypothetical (random) variables or *common factors* [@Jolliffe2002]. The aim of Factor Analysis is to group variables that share a "common theme" under the same grouping, such that the dimensionality of the dataset is decreased.  

Factor Analysis has been applied in psychology to identify groups of inter-related variables, as those components of intelligence that can be placed under a single factor *g* or *general intelligence*, grouping factors such as *broad visual perception* (it includes all the intelligence variables related to visual tasks), or *broad auditory percention* (same as before, but with auditory tasks). This is interpreted as someone with a high *g* having good *broad auditory and visual perceptions*, and *g* sinthetically explaining the behaviour of the factors and variables "contained" within itself.  

This technique is applied here to the given data set.

```{r data_factanal, include=FALSE, echo=FALSE}
#EL VALOR MÁS BAJO ACEPTADO ES DE 0.07
#Extraer los loadings de 210 features. No nombraremos las nuevas features por la complejidad de ello.
data_factanal <- factanal(data_df_predictors, factors = data_optimal_exfeat, scores = "Bartlett", lower = 0.07)
#Utilizar esos loadings para transponer la nueva matriz de factores
data_factanal_exfeat <- data_df_predictors %*% data_factanal$loadings

#Generar los sets de training y test
data_factanal_train <- subset(data_factanal_exfeat[data_train_index,])
data_factanal_test <- subset(data_factanal_exfeat[-data_train_index,])

#Ajustar un SVM con esos factores
data_factanal_svm <- svm(data_factanal_train, y = data_df_train_responses, type = "C-classification", kernel = "radial")
#Predecir con el modelo ajustado las respuestas
data_factanal_predict <- stats::predict(data_factanal_svm, data_factanal_test)
#Tabular datos y sacar Kappa de Cohen
data_factanal_table <- table(data_factanal_predict, data_df_test_responses)
data_factanal_perc_table <- prop.table(data_factanal_table)*100
data_factanal_perc_hit <- sum(diag(data_factanal_perc_table))
data_factanal_cohen <- cohen.kappa(data_factanal_table)
```

After fitting and predicting, the  hit and accuracy values are extracted and represented in **Table 5** and **Table 6**, in absolute and percentage values, respectively.  

```{r data_factanal_table, echo=FALSE, results='asis'}
kable(data_factanal_table, caption = 'Factor Analysis observed versus predicted results', digits = 2, format = "latex")
```
```{r data_factanal_perc_table, echo=FALSE, results='asis'}
kable(data_factanal_perc_table, caption = 'Factor Analysis observed versus predicted results - percentages', digits = 2, format = "latex")
```

This technique gives a weighted Cohen's Kappa Value of `r round(data_factanal_cohen$weighted, 2)`. This value is surprising, given that it puts the **Factor Analysis** technique's accuracy over the **PCA**, which is a peculiar result. This can be a specific case in which **Factor Analysis** is better in a metric sense, while it is clearly more costly in processing power.  

As a visual, informative measure, it is interesting to have the **Factor Analysis** output fitted components plotted, coloured by *tipoCelula* label.  

```{r data_factanal_autoplot, echo=FALSE, results='asis'}
#autoplot(data_factanal, data = data_df, colour = 'tipoCelula')
```

All this said, what **Factor Analysis** does (and what makes it unique) is create a matrix of loadings, this is, it creates columns with synthetic factors that "rely" on and group up subsets of the original variables. These new features are semantic groupings of the original variables, giving this technique an added value as it reveals hidden relations between variables.  

Given these new relationships, it is up to the analyst to name them in a semantically comprising manner (let it be said, as an example, that two theoretical variables "speed" and "agility" were revealed to be bound; the wrapping extracted feature could be named, maybe, "mobility"). In this project these complex relationships won't be named, but given more time, the traits that bind these variables together could be analysed and these new features named.   

##3.4 - LDA  

**Linear Discriminant Analysis**, or **LDA**, is a generalization of *Fisher's Linear Discriminant*. It is a well-known technique for feature extraction, and it has been widely used for such uses as facial recognition, image retrieval or microarray data classification. **LDA** focuses on the response variable classes. It projects the data onto a lower-dimensional vector space such that the ratio of the between-class distance to the within-class distance is maximized, thus achieving maximum discrimination.  

Mathematically, given a data matrix $A \in \R_{N x n}$, classical **LDA** aims to find a transformation $G \in \R_{N x l}$ that maps each column $a_i$ of $A$, for $1 \leq i \leq n$ in the *N*-dimensional space to a vector $b_i$ in the *l*-dimensional space. It creates clusters, such that the quality of each cluster is high if it is well-separated from other clusters and tightly grouped [@Klecka1980].  

This technique is applied here.  

```{r data_lda, include=FALSE, echo=FALSE}
#Pasar por un LDA los predictores
data_lda <- lda(data_df_predictors, grouping = data_df_responses)

#Transformar con los discriminantes lineales el set de predictores.
data_lda_predictors_trans <- data_df_predictors %*% data_lda$scaling

#Generar los sets de training y test
data_lda_train <- subset(data_lda_predictors_trans[data_train_index,])
data_lda_test <- subset(data_lda_predictors_trans[-data_train_index,])

#Ajustar un SVM con esos factores
data_lda_svm <- svm(data_lda_train, y = data_df_train_responses, type = "C-classification", kernel = "radial")
#Predecir con el modelo ajustado las respuestas
data_lda_predict <- stats::predict(data_lda_svm, data_lda_test)
#Tabular datos y sacar Kappa de Cohen
data_lda_table <- table(data_lda_predict, data_df_test_responses)
data_lda_perc_table <- prop.table(data_lda_table)*100
data_lda_perc_hit <- sum(diag(data_lda_perc_table))
data_lda_cohen <- cohen.kappa(data_lda_table)
```

After fitting and predicting, the  hit and accuracy values are extracted and represented in **Table 7** and **Table 8**, in absolute and percentage values, respectively.  

```{r data_lda_table, echo=FALSE, results='asis'}
kable(data_lda_table, caption = 'LDA observed versus predicted results', digits = 2, format = "latex")
```
```{r data_lda_perc_table, echo=FALSE, results='asis'}
kable(data_lda_perc_table, caption = 'LDA observed versus predicted results - percentages', digits = 2, format = "latex")
```

This technique gives a weighted Cohen's Kappa Value of `r round(data_factanal_cohen$weighted, 2)`. It seems a high value is extracted from a data set with well defined class groupings and it may be that, for this application specifically, **LDA** is a good feature reduction technique.  

#4 - Conclussions  

For the time being, **no definitive conclussions** can be extracted from this data. The protocols still need to be refined for the final report of this project, so that possible artifacts and misleading parameters are avoided. If any partial conclussions have to be extracted from this data, it is that the precise area in which these techniques are applied is of an utmost importance to the final utility of each of them, and that no generalisation (e.g. "*PCA is always the best solution*") can be made without an exhaustive eapplication.

#5 - References